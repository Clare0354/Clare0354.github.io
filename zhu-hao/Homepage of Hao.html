<!DOCTYPE html>
<!-- saved from url=(0017)http://zhuhao.cc/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Homepage of Hao">
    <title>Homepage of Hao</title>
    <meta name="author" content="Hao Zhu">
    
    
        <link rel="icon" href="./Homepage of Hao_files/zhuhao2.jpg">
    
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"Website","@id":"","author":{"@type":"Person","name":"Hao Zhu","sameAs":[],"image":"zhuhao2.jpg"},"name":"Homepage of Hao","description":null,"url":""}</script>
    <meta property="og:type" content="blog">
<meta property="og:title" content="Homepage of Hao">
<meta property="og:url" content="/index.html">
<meta property="og:site_name" content="Homepage of Hao">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Homepage of Hao">
    
    
        
    
    
        <meta property="og:image" content="/assets/images/zhuhao2.jpg">
    
    
    
    
    <!--STYLES-->
    <link rel="stylesheet" href="./Homepage of Hao_files/style-kj45bcccii2f4dwk4dklanoync4mtuqwvvy2dxthwcomucjinbik9pxbbwlw.min.css">
    <!--STYLES END-->
    

    

    
</head>

    <body>
        <div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="2" style="">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a class="header-title-link" href="http://zhuhao.cc/" aria-label="">
            Homepage of Hao
        </a>
    </div>
    
        
            <a class="header-right-picture " href="http://zhuhao.cc/#about" aria-label="Open the link: /#about">
        
        
            <img class="header-picture" src="./Homepage of Hao_files/zhuhao2.jpg" alt="Author&#39;s picture">
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="2">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a href="http://zhuhao.cc/#about" aria-label="Read more about the author">
                    <img class="sidebar-profile-picture" src="./Homepage of Hao_files/zhuhao2.jpg" alt="Author&#39;s picture">
                </a>
                <h4 class="sidebar-profile-name">Hao Zhu</h4>
                
                    <h5 class="sidebar-profile-bio"><p>CITE Lab - 3DV Group, Nanjing University<br> E-mail: <a href="mailto:zhuhaoese@nju.edu.cn">zhuhaoese@nju.edu.cn</a></p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a class="sidebar-button-link " href="http://zhuhao.cc/home" title="About Me">
                    
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">About Me</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a class="sidebar-button-link " href="http://zhuhao.cc/" title="Projects">
                    
                        <i class="sidebar-button-icon fa fa-book-reader" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Projects</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a class="sidebar-button-link " href="http://zhuhao.cc/publications" title="Publications">
                    
                        <i class="sidebar-button-icon fa fa-file-alt" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Publications</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a class="sidebar-button-link " href="https://github.com/zhuhao-nju" title="Github">
                    
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Github</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a class="sidebar-button-link " href="https://scholar.google.com/citations?user=YRxe0FkAAAAJ&amp;hl=zh-CN&amp;oi=ao" title="Google Scholar">
                    
                        <i class="sidebar-button-icon fas fa-graduation-cap" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Google Scholar</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="2" class="
                        hasCoverMetaIn
                        ">
                <section class="postShorten-group main-content-wrap">
    
    
    <article class="postShorten postShorten--thumbnailimg-left">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="http://zhuhao.cc/2021/12/01/mofanerf/" aria-label=": MoFaNeRF: Morphable Facial Neural Radiance Field">
                            MoFaNeRF: Morphable Facial Neural Radiance Field
                        </a>
                    
                </h1>
                <div class="postShorten-meta">

</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>We propose a parametric model that maps free-view images into a vector space of coded facial shape, expression and appearance using a neural radiance field, namely Morphable Facial NeRF. MoFaNeRF can be used to synthesize free-view images by fitting to a single image or generating from a random code. The synthesized face is morphable that can be rigged to any expressions and be edited to any shapes or appearances.<br><a href="https://arxiv.org/pdf/2112.02308.pdf" target="_blank" rel="noopener"><i class="fas fa-file-pdf"></i> ECCV 2022 Paper</a>    <a href="https://github.com/zhuhao-nju/mofanerf" target="_blank" rel="noopener"><i class="fab fa-github"></i> Code</a>     <a href="https://neverstopzyy.github.io/mofanerf/" target="_blank" rel="noopener"><i class="fas fa-book-reader"></i> Project Page</a></p>
                    
                </div>
            
        </div>
        
            <a href="http://zhuhao.cc/2021/12/01/mofanerf/" aria-label=": MoFaNeRF: Morphable Facial Neural Radiance Field">
                <div class="postShorten-thumbnailimg">
                    <img alt="" src="./Homepage of Hao_files/mofanerf_title.jpg">
                </div>
            </a>
            
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-left">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="http://zhuhao.cc/2021/11/30/mvfr/" aria-label=": Detailed Facial Geometry Recovery from Multi-view Images by Learning an Implicit Function">
                            Detailed Facial Geometry Recovery from Multi-view Images by Learning an Implicit Function
                        </a>
                    
                </h1>
                <div class="postShorten-meta">

</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>we propose a novel framework to efficiently recover detailed facial geometry from calibrated multi-view images. The cost regression and multi-view fusion is solved by learning an implicit function in our network, which is proved to be more accurate and time-saving.<br><a href="https://arxiv.org/pdf/2201.01016.pdf" target="_blank" rel="noopener"><i class="fas fa-file-pdf"></i> AAAI 2022 Paper (Oral)</a>    <a href="https://github.com/zhuhao-nju/mvfr" target="_blank" rel="noopener"><i class="fab fa-github"></i> Code</a></p>
                    
                </div>
            
        </div>
        
            <a href="http://zhuhao.cc/2021/11/30/mvfr/" aria-label=": Detailed Facial Geometry Recovery from Multi-view Images by Learning an Implicit Function">
                <div class="postShorten-thumbnailimg">
                    <img alt="" src="./Homepage of Hao_files/mvfr_title.jpg">
                </div>
            </a>
            
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-left">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="http://zhuhao.cc/2021/01/01/human_avatar/" aria-label=": Detailed Avatar Recovery from Single Image">
                            Detailed Avatar Recovery from Single Image
                        </a>
                    
                </h1>
                <div class="postShorten-meta">

</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>This paper presents a novel method to recover detailed avatar from a single image.  A learning-based framework is proposed to combine the robustness of the parametric model with the flexibility of free-form 3D deformation. The neural networks are used to refine the 3D shape in a Hierarchical Mesh Deformation (HMD) framework, and restore detailed human body shapes with complete textures beyond skinned models.<br><a href="https://arxiv.org/pdf/2108.02931.pdf" target="_blank" rel="noopener"><i class="fas fa-file-pdf"></i> PAMI 2021 paper</a></p>
                    
                </div>
            
        </div>
        
            <a href="http://zhuhao.cc/2021/01/01/human_avatar/" aria-label=": Detailed Avatar Recovery from Single Image">
                <div class="postShorten-thumbnailimg">
                    <img alt="" src="./Homepage of Hao_files/human_avatar_title.jpg">
                </div>
            </a>
            
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-left">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="http://zhuhao.cc/2021/01/01/pcgc/" aria-label=": Lossy Point Cloud Geometry Compression via End-to-End Learning">
                            Lossy Point Cloud Geometry Compression via End-to-End Learning
                        </a>
                    
                </h1>
                <div class="postShorten-meta">

</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>We explore a novel direction to apply the learningbased framework, consisting of a pre-processing module for point cloud voxelization, scaling and partition, compression network for rate-distortion optimized representation, and a post-processing module for point cloud<br>reconstruction and rendering, to represent point clouds geometry using compact features with the state-of-the-art compression efficiency.<br><a href="https://ieeexplore.ieee.org/document/9321375" target="_blank" rel="noopener"><i class="fas fa-file-pdf"></i> TCSVT 2021 Paper</a>    <a href="https://github.com/NJUVISION/PCGCv1" target="_blank" rel="noopener"><i class="fab fa-github"></i> Code</a></p>
                    
                </div>
            
        </div>
        
            <a href="http://zhuhao.cc/2021/01/01/pcgc/" aria-label=": Lossy Point Cloud Geometry Compression via End-to-End Learning">
                <div class="postShorten-thumbnailimg">
                    <img alt="" src="./Homepage of Hao_files/pcgc_title.jpg">
                </div>
            </a>
            
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-left">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="http://zhuhao.cc/2019/11/02/facescape/" aria-label=": FaceScape: a Large-scale High Quality 3D Face Dataset and Detailed Riggable 3D Face Prediction">
                            FaceScape: a Large-scale High Quality 3D Face Dataset and Detailed Riggable 3D Face Prediction
                        </a>
                    
                </h1>
                <div class="postShorten-meta">

</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>We present FaceScape, a large-scale detailed 3D face dataset consisting of 18,760 textured 3D face model with pore-level geometry. By learning dynamic details from FaceScape, We present a novel algorithm to predict from a single image a detailed rigged 3D face model that can generate various expressions with high geometric details.<br><a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Yang_FaceScape_A_Large-Scale_High_Quality_3D_Face_Dataset_and_Detailed_CVPR_2020_paper.pdf" target="_blank" rel="noopener"><i class="fas fa-file-pdf"></i> CVPR 2020 Paper</a>       <a href="https://github.com/zhuhao-nju/facescape.git" target="_blank" rel="noopener"><i class="fab fa-github"></i> Code &amp; Dataset</a></p>
                    
                </div>
            
        </div>
        
            <a href="http://zhuhao.cc/2019/11/02/facescape/" aria-label=": FaceScape: a Large-scale High Quality 3D Face Dataset and Detailed Riggable 3D Face Prediction">
                <div class="postShorten-thumbnailimg">
                    <img alt="" src="./Homepage of Hao_files/facescape_title.jpg">
                </div>
            </a>
            
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-left">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="http://zhuhao.cc/2019/11/01/self-supervised_human/" aria-label=": Self-Supervised Human Depth Estimation from Monocular Videos">
                            Self-Supervised Human Depth Estimation from Monocular Videos
                        </a>
                    
                </h1>
                <div class="postShorten-meta">

</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>This paper presents a self-supervised method that can be trained on videos without known depth, which makes training data collection simple and improves the generalization of the learned network. The self-supervised learning is achieved by minimizing a photo-consistency loss between a video frame and its neighboring frames.<br><a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Tan_Self-Supervised_Human_Depth_Estimation_From_Monocular_Videos_CVPR_2020_paper.pdf" target="_blank" rel="noopener"><i class="fas fa-file-pdf"></i> CVPR 2020 Paper</a>       <a href="https://github.com/sfu-gruvi-3dv/Self-Supervised-Human-Depth.git" target="_blank" rel="noopener"><i class="fab fa-github"></i> Code</a></p>
                    
                </div>
            
        </div>
        
            <a href="http://zhuhao.cc/2019/11/01/self-supervised_human/" aria-label=": Self-Supervised Human Depth Estimation from Monocular Videos">
                <div class="postShorten-thumbnailimg">
                    <img alt="" src="./Homepage of Hao_files/self-supervised_human_title.jpg">
                </div>
            </a>
            
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-left">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="http://zhuhao.cc/2019/10/01/speech2video/" aria-label=": Speech2Video: Synthesis with 3D Skeleton Regularization and Expressive Body Poses">
                            Speech2Video: Synthesis with 3D Skeleton Regularization and Expressive Body Poses
                        </a>
                    
                </h1>
                <div class="postShorten-meta">

</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>We propose a novel approach to convert given speech audio to a photo-realistic speaking video of a specific person, where the output video has synchronized, realistic, and expressive rich body dynamics. The system is  achieved by first generating 3D skeleton movements from the audio using a RNN, then synthesizing the output video via a conditional GAN.<br><a href="https://arxiv.org/pdf/2007.09198.pdf" target="_blank" rel="noopener"><i class="fas fa-file-pdf"></i> ACCV 2020 Paper</a></p>
                    
                </div>
            
        </div>
        
            <a href="http://zhuhao.cc/2019/10/01/speech2video/" aria-label=": Speech2Video: Synthesis with 3D Skeleton Regularization and Expressive Body Poses">
                <div class="postShorten-thumbnailimg">
                    <img alt="" src="./Homepage of Hao_files/speech2video_title.jpg">
                </div>
            </a>
            
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-left">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="http://zhuhao.cc/2019/06/01/human_shape/" aria-label=": Human Shape Estimation from a Single Image by Hierarchical Mesh Deformation">
                            Human Shape Estimation from a Single Image by Hierarchical Mesh Deformation
                        </a>
                    
                </h1>
                <div class="postShorten-meta">

</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>We propose a novel learning based framework that combines the robustness of parametric model with the flexibility of free-form 3D deformation.  We use the deep neural networks to refine the 3D shape in a Hierarchical Mesh Deformation (HMD) framework, utilizing the constraints from body joints, silhouettes, and shading information.<br><a href="https://cite.nju.edu.cn/DFS//file/2019/07/17/20190717192558589gklhs8.pdf" target="_blank" rel="noopener"><i class="fas fa-file-pdf"></i> CVPR 2019 paper (oral)</a>    <a href="https://github.com/zhuhao-nju/hmd.git" target="_blank" rel="noopener"><i class="fab fa-github"></i> Code</a>    <a href="https://cite.nju.edu.cn/Researches/3DCaptureandReconstruction/20190621/i5141.html" target="_blank" rel="noopener"><i class="fas fa-book-reader"></i> Project Page</a></p>
                    
                </div>
            
        </div>
        
            <a href="http://zhuhao.cc/2019/06/01/human_shape/" aria-label=": Human Shape Estimation from a Single Image by Hierarchical Mesh Deformation">
                <div class="postShorten-thumbnailimg">
                    <img alt="" src="./Homepage of Hao_files/human_shape_title.jpg">
                </div>
            </a>
            
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-left">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="http://zhuhao.cc/2018/06/01/view_synthesis/" aria-label=": View Extrapolation of Human Body from a Single Image">
                            View Extrapolation of Human Body from a Single Image
                        </a>
                    
                </h1>
                <div class="postShorten-meta">

</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>We study how to synthesize novel views of human body from a single image. Our new pipeline is a composition of a shape estimation network and an image generation network, and at the interface a perspective transformation is applied to generate a forward flow for pixel value transportation.<br><a href="https://cite.nju.edu.cn/DFS//file/2019/07/18/20190718204619284ccj5a6.pdf" target="_blank" rel="noopener"><i class="fas fa-file-pdf"></i> CVPR 2018 paper</a>     <a href="https://cite.nju.edu.cn/Researches/3DCaptureandReconstruction/20190621/i5139.html" target="_blank" rel="noopener"><i class="fas fa-book-reader"></i> Project Page</a></p>
                    
                </div>
            
        </div>
        
            <a href="http://zhuhao.cc/2018/06/01/view_synthesis/" aria-label=": View Extrapolation of Human Body from a Single Image">
                <div class="postShorten-thumbnailimg">
                    <img alt="" src="./Homepage of Hao_files/view_synthesis_title.jpg">
                </div>
            </a>
            
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-left">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="http://zhuhao.cc/2017/06/01/video_human/" aria-label=": Video based Outdoor Human Reconstruction">
                            Video based Outdoor Human Reconstruction
                        </a>
                    
                </h1>
                <div class="postShorten-meta">

</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>We propose a very convenient system of scanning a human body using only a conventional video camera without the aid of special sensor or controlled illumination.  The point cloud reinforcement is proposed to detect and adjust the conflict point data for the slender and shaky body part, which achieves reasonable and plausible mesh reconstruction.<br><a href="https://cite.nju.edu.cn/DFS//file/2019/07/17/20190717192639218ri239e.pdf" target="_blank" rel="noopener"><i class="fas fa-file-pdf"></i> TCSVT 2017 paper</a>      <a href="https://cite.nju.edu.cn/Researches/3DCaptureandReconstruction/20190621/i5136.html" target="_blank" rel="noopener"><i class="fas fa-book-reader"></i> Project Page</a>  </p>
                    
                </div>
            
        </div>
        
            <a href="http://zhuhao.cc/2017/06/01/video_human/" aria-label=": Video based Outdoor Human Reconstruction">
                <div class="postShorten-thumbnailimg">
                    <img alt="" src="./Homepage of Hao_files/video_human_title.jpg">
                </div>
            </a>
            
        
    </article>
    
    <div class="pagination-bar">
    <ul class="pagination">
        
        
          <li class="pagination-next">
            <a class="btn btn--default btn--small" href="http://zhuhao.cc/page/2/" aria-label="OLDER POSTS">
              <span>OLDER POSTS</span>
              <i class="fa fa-angle-right text-base icon-ml"></i>
            </a>
          </li>
        
        <li class="pagination-number">page 1 of 2</li>
    </ul>
</div>

</section>


                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights © 2022 Hao Zhu. All Rights Reserved.   <a href="https://beian.miit.gov.cn/">苏ICP备2022030647号-1</a>   </span>
</footer>

            </div>
            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="./Homepage of Hao_files/zhuhao2.jpg" alt="Author&#39;s picture">
        
            <h4 id="about-card-name">Hao Zhu</h4>
        
            <div id="about-card-bio"><p>CITE Lab - 3DV Group, Nanjing University<br> E-mail: <a href="mailto:zhuhaoese@nju.edu.cn">zhuhaoese@nju.edu.cn</a></p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br>
                <p>Associate Researcher</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br>
                Nanjing, China
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url(&#39;/assets/images/lines.jpg&#39;);"></div>
        <!--SCRIPTS-->
<script src="./Homepage of Hao_files/script-8jvys96ppmoewecwgcu3ze8zjru56s9o5rbuwy1hndmnter2gmnlvqtdm0oj.min.js.下载"></script>
<!--SCRIPTS END-->





    

</body></html>